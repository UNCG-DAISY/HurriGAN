{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribution: this code was written by Andres Pitta, Braden Tam, Florence Wang, Hanying Zhang, Tomas Beuzen\n",
    "\n",
    "# General\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "# For modeling the Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Reshape, Conv2DTranspose, GaussianNoise\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "# For images \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from IPython import display\n",
    "\n",
    "# For the labels\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cdcgans():\n",
    "  \"\"\"\n",
    "  Conditional DCGANS.\n",
    "  \"\"\"\n",
    "  def __init__(self, img_size, noise_dim = 100, n_classes = 10,\n",
    "               lr_g = 0.0002, lr_d = 0.0002, beta1 = 0.5, num_examples_to_generate = 10,\n",
    "               epochs = 50, batch_size = 32, dropout_rate = 0.3, restore_checkpoint = False,\n",
    "               save_ckpt_path = './training_checkpoints', load_ckp_path = './training_checkpoints',\n",
    "               city_names = ['Boston']):\n",
    "    '''\n",
    "    Init function.\n",
    "    Parameters\n",
    "    --------------\n",
    "    img_size (int):\n",
    "        Input image size (width and height)\n",
    "    noise_dim (int):\n",
    "        Input noise dimension to generate fake image (latent dimension).\n",
    "        Default 100.\n",
    "    n_classes (int):\n",
    "        Total number of classes (label) in the dataset.\n",
    "        Default 10.\n",
    "    lr_g (float):\n",
    "        Adam optimizer learning rate for generator network.\n",
    "        Default 0.0002.\n",
    "    lr_d (float):\n",
    "        Adam optimizer learning rate for discriminator network.\n",
    "        Default 0.0002.\n",
    "    beta1 (float):\n",
    "        The exponential decay rate for the 1st moment estimates in Adam optimizer.\n",
    "        Default 0.5.\n",
    "    num_examples_to_generate (int):\n",
    "        Number of images to generate along with training.\n",
    "        Default 10.\n",
    "    epochs (int):\n",
    "        Number of epochs.\n",
    "        Default 50.\n",
    "    batch_size (int):\n",
    "        Batch size used in the dataset.\n",
    "        Dafault 32.\n",
    "    dropout_rate (float):\n",
    "        Percentage to dropout in the discriminator network.\n",
    "        Default 0.3.\n",
    "    restore_checkpoint (bool):\n",
    "        Whether to restore checkpoints.\n",
    "        Default False.\n",
    "    save_ckpt_path (str):\n",
    "        Folder path to save checkpoints.\n",
    "        Default ./training_checkpoints.\n",
    "    load_ckp_path (str):\n",
    "        Folder path to restore checkpoints.\n",
    "        Default ./training_checkpoints.\n",
    "    city_names (list):\n",
    "        Name of the conditioning label\n",
    "        Default ['Boston']\n",
    "    \n",
    "    '''\n",
    "    # data input\n",
    "    self.img_size = img_size\n",
    "    self.channels = 3\n",
    "    self.noise_dim = noise_dim\n",
    "    self.n_classes = n_classes\n",
    "    self.city_names = city_names\n",
    "\n",
    "    # epochs and batches\n",
    "    self.epochs = epochs\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    # build generator and discriminator\n",
    "    self.generator = self.make_generator_model()\n",
    "    self.discriminator = self.make_discriminator_model(dropout_rate)\n",
    "    \n",
    "    # set optimizer   \n",
    "    self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate = lr_g, beta_1 = beta1)\n",
    "    self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = lr_d, beta_1 = beta1)\n",
    "\n",
    "    # We will reuse this seed overtime\n",
    "    # to visualize progress in the animated GIF)\n",
    "    self.seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "    # checkpoints \n",
    "    # save checkpoint\n",
    "    checkpoint_dir = save_ckpt_path\n",
    "    self.checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    self.checkpoint = tf.train.Checkpoint(generator_optimizer=self.generator_optimizer,\n",
    "                                discriminator_optimizer=self.discriminator_optimizer,\n",
    "                                generator=self.generator,\n",
    "                                discriminator=self.discriminator)\n",
    "    # load checkpoint\n",
    "    if restore_checkpoint:\n",
    "      self.checkpoint.restore(tf.train.latest_checkpoint(load_ckp_path))\n",
    "      print('Successfully restored checkpoint!')\n",
    "\n",
    "  #generator model\n",
    "  def make_generator_model(self):\n",
    "    '''\n",
    "    Build tensorflow architecture of generator model.\n",
    "    '''\n",
    "    # note: layers shape depends on image size\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(self.img_size // 4 * self.img_size // 4 * 512, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((self.img_size // 4, self.img_size // 4, 512)))\n",
    "    assert model.output_shape == (None, self.img_size // 4, self.img_size // 4, 512)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, self.img_size // 4, self.img_size // 4, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, self.img_size // 2, self.img_size // 2, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, self.img_size, self.img_size, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, self.img_size, self.img_size, 3)\n",
    "    model.summary()\n",
    "\n",
    "    noise=layers.Input(shape=(100,))\n",
    "    \n",
    "    label=layers.Input(shape=(1,))\n",
    "    label_embedding=layers.Flatten()(layers.Embedding(self.n_classes, 100)(label))\n",
    "    \n",
    "    model_input=layers.multiply([noise, label_embedding])\n",
    "\n",
    "    img=model(model_input)\n",
    "    generator_model = Model([noise,label],img)\n",
    "\n",
    "    generator_model.summary()\n",
    "    return generator_model\n",
    "\n",
    "  # discriminator model\n",
    "  def make_discriminator_model(self, dropout_rate):\n",
    "    '''\n",
    "    Build tensorflow architecture of discriminator model.\n",
    "    Parameters\n",
    "    --------------\n",
    "    dropout_rate (float):\n",
    "        Percentage to dropout.\n",
    "    '''\n",
    "    in_label = layers.Input(shape=(1,))\n",
    "    in_label = layers.Input(shape=(1,))\n",
    "    in_image = layers.Input(shape=(self.img_size, self.img_size, self.channels))\n",
    "\n",
    "    model = GaussianNoise(0.2)(in_image)\n",
    "    model = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(model)\n",
    "    model = layers.LeakyReLU()(model)\n",
    "    model = layers.Dropout(dropout_rate)(model)\n",
    "    \n",
    "    model = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(model)\n",
    "    model = layers.LeakyReLU()(model)\n",
    "    model = layers.Dropout(dropout_rate)(model)\n",
    "\n",
    "    model = layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same')(model)\n",
    "    model = layers.LeakyReLU()(model)\n",
    "    model = layers.Dropout(dropout_rate)(model)\n",
    "\n",
    "    model = layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same')(model)\n",
    "    model = layers.LeakyReLU()(model)\n",
    "    model = layers.Dropout(dropout_rate)(model)\n",
    "\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1000)(model)\n",
    "    model = layers.LeakyReLU()(model)\n",
    "    model = layers.Dropout(dropout_rate)(model)\n",
    "    li = layers.Embedding(self.n_classes, 1000)(in_label)\n",
    "    li = layers.Flatten()(li)\n",
    "\n",
    "    merge = layers.Multiply()([model, li])\n",
    "\n",
    "    model = layers.Dense(512)(merge)\n",
    "    model = layers.LeakyReLU(0.2)(model)\n",
    "    model = layers.Dropout(0.3)(model)\n",
    "    out = layers.Dense(1)(model)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[in_image,in_label], outputs=out)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "    # discriminator loss function\n",
    "  def discriminator_loss(self, real_output, fake_output):\n",
    "    '''\n",
    "    Calculates binary crossentropy loss for discriminator.\n",
    "    Parameters\n",
    "    -------------------\n",
    "    real_output (tensorflow numpy array):\n",
    "        Discriminator output from fitting real images.\n",
    "    fake_output (tensorflow numpy array):\n",
    "        Discriminator output from fitting fake images.\n",
    "    Returns\n",
    "    ---------------\n",
    "        Average binary crossentropy loss of discriminator.\n",
    "    '''\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    \n",
    "    return tf.reduce_mean(0.5*total_loss)\n",
    "    \n",
    "  # generator loss function\n",
    "  def generator_loss(self, fake_output):\n",
    "    '''\n",
    "    Calculates binary crossentropy loss for generator.\n",
    "    Parameters\n",
    "    -------------------\n",
    "    fake_output (tensorflow numpy array):\n",
    "        Discriminator output from fitting fake images.\n",
    "    Returns\n",
    "    ---------------\n",
    "        Average binary crossentropy loss of generator.   \n",
    "    '''\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    return tf.reduce_mean(cross_entropy(tf.ones_like(fake_output), fake_output))  \n",
    "  \n",
    "  # Notice the use of `tf.function`\n",
    "  # This annotation causes the function to be \"compiled\".\n",
    "  @tf.function\n",
    "  def train_step(self, images, labels):\n",
    "    '''\n",
    "    Compile generator and discriminator.\n",
    "    Parameters\n",
    "    -------------------\n",
    "    images (np.array):\n",
    "        Training images.\n",
    "    labels (np.array):\n",
    "        Labels of images.\n",
    "    Returns\n",
    "    ---------------\n",
    "    gen_loss (float):\n",
    "        Average binary crossentropy loss of generator.\n",
    "    disc_loss (float):\n",
    "        Average binary crossentropy loss of generator.\n",
    "    fake_output (tensorflow numpy array):\n",
    "        Discriminator output from fitting fake images.\n",
    "    '''\n",
    "    noise = tf.random.normal([self.batch_size, self.noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = self.generator([noise,labels], training=True)\n",
    "\n",
    "      real_output = self.discriminator([images,labels], training=True)\n",
    "      fake_output = self.discriminator([generated_images,labels], training=True)\n",
    "\n",
    "      gen_loss = self.generator_loss(fake_output)\n",
    "      disc_loss = self.discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "    self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "    self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss, fake_output\n",
    "    \n",
    "  # train the model\n",
    "  def train(self, dataset, steps_per_epoch, labels,\n",
    "            saving_gap = 15,\n",
    "            save_img = True, img_path = './generated_imgs', \n",
    "            save_loss_batch = False, save_loss_epoch = True, loss_path = './losses'):\n",
    "    '''\n",
    "    Train the model and print results over each epochs.\n",
    "    Parameters\n",
    "    ------------------- \n",
    "    dataset (np.array, np.array):\n",
    "        Image generator tuple with the images and its labels (images, labels).  \n",
    "    steps_per_epoch (int):\n",
    "        Number of steps per epoch (total images / batch size).\n",
    "    labels (np.array):\n",
    "        Input labels for sample images to generate.\n",
    "    saving_gap (int):\n",
    "        Gaps to save checkpoints, images and losses over epochs. Default 15.\n",
    "    save_img (bool):\n",
    "        Whether to save images produced by 'generate_and_save_images' function \n",
    "        for each 'saving_gap' epochs. Default True.\n",
    "    img_path (str):\n",
    "        Folder path to save images. Default './generated_imgs'.\n",
    "    save_loss_batch (bool):\n",
    "        Whether to save plots of losses over batches produced by 'summarize_epoch' function \n",
    "        for each 'saving_gap' epochs. Default False.\n",
    "    save_loss_epoch (bool):\n",
    "        Whether to save the plot of total loss over epochs produced by 'plot_loss_over_epoch' function.\n",
    "        Default True.\n",
    "    loss_path (str):\n",
    "        Folder path to save losses. Default './losses'.\n",
    "    '''\n",
    "\n",
    "    # save losses over epochs\n",
    "    losses_on_epoch = {'g_losses' :[], 'd_losses': [], 'epochs': [],'perc_fake_true':[]}\n",
    "\n",
    "    for epoch in range(self.epochs):\n",
    "      print(f\"Starting epoch {epoch+1}.\")\n",
    "      start = time.time()\n",
    "      #save losses over batches\n",
    "      g_losses = []\n",
    "      d_losses = []\n",
    "      num_fake_true = [] # number of classify fake image as real\n",
    "\n",
    "      batch = 0\n",
    "\n",
    "      for image_batch, image_label in dataset: \n",
    "        if batch % 50 == 0:\n",
    "          print(f\"  Starting batch {batch+1}/{steps_per_epoch}\")\n",
    "        # training part\n",
    "        g_loss, d_loss, fake_arr = self.train_step(image_batch,image_label)\n",
    "        # get number of images that fools discriminator\n",
    "        fake_true = np.sum(fake_arr.numpy() > 0) \n",
    "        # append losses over batches\n",
    "        g_losses.append(g_loss.numpy())\n",
    "        d_losses.append(d_loss.numpy())\n",
    "        num_fake_true.append(fake_true)##\n",
    "\n",
    "        batch += 1\n",
    "        if batch >= steps_per_epoch:\n",
    "          break\n",
    "      print(\"  Done train step.\")\n",
    "\n",
    "      # Produce images for the GIF as we go\n",
    "      display.clear_output(wait=True)\n",
    "      # save images for each epoch\n",
    "      self.generate_and_save_images(self.generator,\n",
    "                              epoch + 1,\n",
    "                              self.seed,\n",
    "                              labels,\n",
    "                              img_path,\n",
    "                              save_img,\n",
    "                              1)\n",
    "      \n",
    "      # Save the model every 15 epochs\n",
    "      if saving_gap != 0:\n",
    "        if ((epoch + 1) % saving_gap == 0) | ((epoch + 1) == self.epochs):\n",
    "          self.checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
    "      # plot loss on each epoch\n",
    "      g_loss_mean, d_loss_mean, perc_fake_true = self.summarize_epoch(epoch, \n",
    "                                                                      d_losses, g_losses, \n",
    "                                                                      steps_per_epoch,\n",
    "                                                                      num_fake_true,\n",
    "                                                                      loss_path,\n",
    "                                                                      save_loss_batch,\n",
    "                                                                      saving_gap)\n",
    "      # save the losses\n",
    "      losses_on_epoch['g_losses'].append(g_loss_mean)\n",
    "      losses_on_epoch['d_losses'].append(d_loss_mean)\n",
    "      losses_on_epoch['epochs'].append(epoch + 1)\n",
    "      losses_on_epoch['perc_fake_true'].append(perc_fake_true)\n",
    "      \n",
    "      print ('Time taken for epoch {} is {} sec.'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    self.generate_and_save_images(self.generator,\n",
    "                            self.epochs,\n",
    "                            self.seed,\n",
    "                            labels,\n",
    "                            img_path,\n",
    "                            True, # default save last image\n",
    "                            saving_gap)\n",
    "    # plot loss after all epochs\n",
    "    self.plot_loss_over_epoch(losses_on_epoch['g_losses'],losses_on_epoch['d_losses'],losses_on_epoch['epochs'], \n",
    "                        losses_on_epoch['perc_fake_true'],\n",
    "                        loss_path,save_loss_epoch)\n",
    "    # print loss after all epochs\n",
    "    print('g_loss: {} \\nd_loss: {} \\npercentage of classify fake image as real: {}'.format(\n",
    "        losses_on_epoch['g_losses'][-1],\n",
    "        losses_on_epoch['d_losses'][-1],\n",
    "        losses_on_epoch['perc_fake_true'][-1]))\n",
    "    \n",
    "  #produce a new image\n",
    "  def produce_image(self,label):\n",
    "    '''\n",
    "    Generate a new fake image and plot the image.\n",
    "    Parameters\n",
    "    ------------------- \n",
    "    label (np.array):\n",
    "        The label for the image to generate (1-D numpy array with lenghth 1).\n",
    "    \n",
    "    Returns\n",
    "    ------------------- \n",
    "    img_array (np.array):\n",
    "        Numpy array of the generated image.\n",
    "    '''\n",
    "    generator = self.generator\n",
    "    noise = tf.random.normal([1, self.noise_dim])\n",
    "    generated_image = generator([noise,np.array([label])], training=False)\n",
    "    img_array = generated_image[0, :, :].numpy()\n",
    "    img_array = (img_array - np.min(img_array))/np.ptp(img_array)\n",
    "    plt.imshow(img_array)\n",
    "    return img_array\n",
    "\n",
    "  ### below are functions used in the train function\n",
    "\n",
    "  # function used in train\n",
    "  def generate_and_save_images(self, model, epoch, test_input, labels, \n",
    "                               img_path, save_img = True,saving_gap = 15):\n",
    "    '''\n",
    "    Generate, plot and save fake images with subplot 3x3 along with training. \n",
    "    Parameters\n",
    "    ------------------- \n",
    "    model (tensorflow model):\n",
    "        The generator used to generate images.\n",
    "    epoch (int):\n",
    "        Current epoch in training step.\n",
    "    test_input (np.array): \n",
    "        The input random noise to generate image.\n",
    "    labels (np.array):\n",
    "        The input labels for sample images to generate.\n",
    "    img_path (str):\n",
    "        Folder path to save images.\n",
    "    save_img (bool):\n",
    "        Whether to save images for each 'saving_gap' epochs. Default True.\n",
    "    saving_gap (int):\n",
    "        Gaps to save checkpoints, images and losses over epochs. Default 15.\n",
    "    '''\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    fig = plt.figure(figsize=(8,10))\n",
    "    fig.suptitle(f'Generation at epoch {epoch}', fontsize=12)\n",
    "    labels_enc = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        predictions = model([test_input,np.array([labels_enc[i]]).reshape((-1,1))], training=False)\n",
    "        plt.subplot(5, 2, i+1) ## NOTE: This depends on num_examples_to_generate\n",
    "        p = predictions[0, :, :]\n",
    "        p = (p - np.min(p))/np.ptp(p)\n",
    "        plt.imshow(p)\n",
    "        plt.title('label: {}'.format(self.city_names[i]))\n",
    "        plt.axis('off')\n",
    "    if (save_img) & (saving_gap != 0):\n",
    "      # save images on each 15 epochs\n",
    "      if (epoch == 0 ) | ((epoch + 1) % saving_gap == 0) | ((epoch) == self.epochs):\n",
    "          plt.savefig(img_path + '/image_at_epoch_{:04d}.png'.format(epoch+1))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "  # function used in train\n",
    "  # plot loss after all epochs\n",
    "  def plot_loss_over_epoch(self, g_losses,d_losses,epochs, fake_true,\n",
    "                           loss_path, save_loss_epoch = True):\n",
    "    '''\n",
    "    Plot and save total loss over epochs after training. \n",
    "    Parameters\n",
    "    ------------------- \n",
    "    g_losses (list):\n",
    "        Generator losses over epochs.\n",
    "    d_losses (list):\n",
    "        Discriminator losses over epochs.\n",
    "    fake_true (list):\n",
    "        Percentage of fake images that fools discriminator over epochs.\n",
    "    loss_path (str):\n",
    "        Folder path to save losses.\n",
    "    save_loss_epoch (bool):\n",
    "        Whether to save the plot of total loss over epochs. Default True.\n",
    "    '''\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(g_losses, label='Generator', alpha=0.6)\n",
    "    plt.plot(d_losses, label='Discriminator', alpha=0.6)\n",
    "    #plt.plot(fake_true, label = 'perc of fools', alpha=0.6)\n",
    "    plt.title(\"Losses\")\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "    if save_loss_epoch:\n",
    "      plt.savefig(loss_path +'/{:04d}_epochs_losses.png'.format(epochs[-1]))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "  \n",
    "  # function used in train\n",
    "  # reference: https://github.com/gsurma/image_generator/blob/master/ImageGeneratorDCGAN.ipynb\n",
    "  # plot loss on the each epoch\n",
    "  def summarize_epoch(self, epoch, g_losses, d_losses, steps_per_epoch, fake_true,\n",
    "                      loss_path, save_loss_batch = False, saving_gap = 15):\n",
    "      '''\n",
    "      Plot and save fake loss over bathces in each epoch along with training.\n",
    "      Parameters\n",
    "      ------------------- \n",
    "      epoch (int):\n",
    "          Current epoch in training step.\n",
    "      g_losses (list):\n",
    "        Generator losses over batches on current epoch.\n",
    "      d_losses (list):\n",
    "        Discriminator losses over batches on current epoch.\n",
    "      fake_true (list):\n",
    "        Percentage of fake images that fools discriminator over batches on current epoch.\n",
    "      loss_path (str):\n",
    "        Folder path to save losses.\n",
    "      save_loss_batch (bool):\n",
    "        Whether to save plots of losses over batches for each 'saving_gap' epochs. Default False.\n",
    "      saving_gap (int):\n",
    "          Gaps to save checkpoints, images and losses over epochs. Default 15.\n",
    "      '''\n",
    "      g_loss_mean = np.mean(g_losses[-steps_per_epoch:])\n",
    "      d_loss_mean = np.mean(d_losses[-steps_per_epoch:])\n",
    "      perc_fake_true = np.sum(fake_true)/(steps_per_epoch * self.batch_size)\n",
    "      print(\"Epoch {}/{}\".format(epoch + 1, self.epochs),\n",
    "            \"\\nG Loss: {:.5f}\".format(g_loss_mean),\n",
    "            \"\\nD Loss: {:.5f}\".format(d_loss_mean),\n",
    "            \"\\nPercent of fake true: {:.5f}\".format(perc_fake_true))#\n",
    "      fig, ax = plt.subplots()\n",
    "      plt.plot(g_losses, label='Generator', alpha=0.6)\n",
    "      plt.plot(d_losses, label='Discriminator', alpha=0.6)\n",
    "      #percent of fake true over epochs\n",
    "      perc_fake_true_batch = [i/self.batch_size for i in fake_true]\n",
    "      plt.plot(perc_fake_true_batch, label = 'perc of fools',alpha = 0.6)\n",
    "\n",
    "      plt.title(\"Losses\")\n",
    "      plt.legend()\n",
    "      # save losses each 15 epochs\n",
    "      if (save_loss_batch) & (saving_gap != 0) :\n",
    "        if (epoch ==0 ) | ((epoch + 1) % saving_gap == 0) | (epoch == self.epochs):\n",
    "          plt.savefig(loss_path + '/losses_at_epoch_{:04d}.png'.format(epoch+1))\n",
    "      plt.show()\n",
    "      plt.close()\n",
    "      return g_loss_mean, d_loss_mean, perc_fake_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 320000)            32000000  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 320000)            1280000   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 320000)            0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 25, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 25, 25, 256)       3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 25, 25, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 50, 50, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 50, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 100, 100, 64)      204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100, 100, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 100, 100, 3)       4800      \n",
      "=================================================================\n",
      "Total params: 37,587,392\n",
      "Trainable params: 36,946,496\n",
      "Non-trainable params: 640,896\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 100)       1000        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100)          0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 100)          0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 100, 100, 3)  37587392    multiply[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,588,392\n",
      "Trainable params: 36,947,496\n",
      "Non-trainable params: 640,896\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 100, 100, 3)  0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 50, 50, 64)   4864        gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 50, 50, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 64)   0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 25, 25, 128)  204928      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 25, 25, 128)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 128)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 13, 13, 256)  819456      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 13, 13, 256)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 13, 13, 256)  0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 512)    3277312     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 7, 7, 512)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 512)    0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 25088)        0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1000)         25089000    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 1000)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 1000)      10000       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000)         0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1000)         0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1000)         0           dropout_5[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          512512      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            513         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,918,585\n",
      "Trainable params: 29,918,585\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.cdcgans at 0x1a33b09710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdcgans(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
